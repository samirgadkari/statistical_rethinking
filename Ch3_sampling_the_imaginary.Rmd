---
title: "Ch3_sampling_the_imaginary"
author: "Samir Gadkari"
date: "4/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rethinking)
```

## 3.1 Sampling from a grid-approximate posterior

Let's sample from the posterior of the globe-tossing model using grid approximation to see the distribution of the posterior samples.

```{r}
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prob_prior <- rep(1, 1000)
prob_data <- dbinom(6, 9, prob = p_grid)
posterior <- prob_prior * prob_data
posterior <- posterior / sum(posterior)

samples <- sample(p_grid,            # sample from the grid,
                  prob = posterior,  # using posterior probability
                  size = 1e4,
                  replace = TRUE)
plot(samples)
dens(samples)
```

## 3.2 Sampling to summarize the posterior
```{r}
str(posterior)
label_values = seq(0, 1000, 200)
plot(posterior,
     xaxt = "n",  # Don't show x axis
     xlab = "p_grid")
axis(1,           # 1 = below, 2 = left, 3 = above, 4 = right
     at = label_values,
     labels = as.character(round(label_values/1000, 2)))
```
### 3.2.1 Intervals of defined boundaries

Find the posterior probability where the proportion of water < 0.5.

```{r}
sum(posterior[p_grid < 0.5])
```
This is not easy to do when there are many parameters in the posterior distribution. So let's try getting this value by sampling the posterior. This process can be used with any number of parameters in the posterior.

```{r}
sum(samples < 0.5) / 1e4
```

The answer is almost the same as the actual posterior probability.

How much posterior probability lies between 0.5 and 0.75?
```{r}
sum((samples > 0.5) & (samples < 0.75))/ 1e4
```

### 3.2.2 Intervals of defined mass

Compatibility interval is usually called confidence interval, except we should not develop confidence in a standard procedure without thinking of what it means in real life. So we will call it the compatibility interval.

To find the lower 80 percent of the posterior distribution:
```{r}
quantile(samples, 0.8)
```
The middle 80 percent lies between 0.1 and 0.9 (the 10th and 90th percentile).
```{r}
quantile(samples, c(0.1, 0.9))
PI(samples, prob = 0.8)        # rethinking package function finds the middle
                               # x% range.
```

Such intervals provide a description of the distribution as long as the distribution is approximately symmetrical. Let's try a non-symmetrical distribution for the globe toss example with 3 out of 3 events of water.
```{r}
p_grid <- seq(0, 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(3, size = 3, prob = p_grid)
posterior <- prior * likelihood
posterior <- posterior / sum(posterior)
samples <- sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)

plot(p_grid, posterior)
```

```{r}
PI(samples, prob = 0.5)
```

But this range does not include the maximum probability (at 1). Instead, use HPDI function (High posterior density interval) to find this range.

```{r}
HPDI(samples, prob = 0.5)
```

The HPDI is sensitive to the number of samples you draw from the posterior (also called the simulation variance). If the choice of interval type makes a difference, just plot the entire posterior.

### 3.2.3 Point estimates

Point estimates of a posterior gives a single value to describe the posterior. Point estimates of a posterior discards information about it. So, you should not use it unless it is really necessary. To specify a point estimate, we must specify a loss function. Different loss functions nominate different point estimates.

To find the MAP (Maximum a Posteriori) for the 3 waters out of 3 tosses example:
```{r}
which.max(posterior)
p_grid[which.max(posterior)]
```

To use samples to find the MAP:
```{r}
# Find the mode from samples
chainmode(samples,     # values sampled from posterior
          adj = 0.01)
```

Mean and median:
```{r}
mean(samples)
median(samples)
```

So which do we choose? Mode, mean, median?
If you're using the absolute error as the criteria, then the median of the samples minimizes the loss function. If using the euclidean distance as the loss, the mean of the sample minimizes the loss function:
```{r}
median_loss_fn <- function(d) {
  sum(posterior * abs(d - p_grid))
}

loss <- sapply(p_grid, median_loss_fn)
p_grid[which.min(loss)]
```
```{r}
mean_loss_fn <- function(d) {
  sum(posterior * ((d - p_grid)^2))
}

loss <- sapply(p_grid, mean_loss_fn)
p_grid[which.min(loss)]
```

```{r}
plot(p_grid, posterior)
abline(v = median(samples), col = "blue")
abline(v = mean(samples), col = "red")

plot(p_grid, sapply(p_grid, median_loss_fn), 
     lty = 1, lwd = 2, 
     col = "blue",
     ylim = c(0, 0.2),
     ylab = "Absolute loss (blue) and Quadratic loss (red)")
lines(p_grid, sapply(p_grid, mean_loss_fn), lty = 1, lwd = 2, col = "red")
```

## 3.3 Sampling to simulate prediction

Generating implied observations from a model is useful for:

  * Model design: Sampling from the prior will tell us what the model expects. This is most useful when there are multiple parameters, so that the joint distribution needs to be sampled to be understood.
  * Model checking: After updating a model with data, generate sample observations from the model to:
    * check if the model works correctly
    * investigate model behavior
  * Software validation: To ensure model-fitting software is valid,
    * generate observations from the model
    * recover values of the parameters, and check against values of the original data
  * Research design: If you can simulate observations from your hypothesis, you can evaluate whether the research can be effective. This means it is not just power analysis, but much more.
  * Forecasting: Simulate new predictions for new cases and future observations. These forecasts are useful for
    * applied prediction
    * model criticism and revision
    
### 3.3.1 Dummy data

We will simulate the globe tossing model.

Likelihood is bi-directional:
  * Given a realized observation, the likelihood says how plausible it is
  * Given model parameters, the likelihood gives us a distribution of the possible observations
  
Binomial distribution: 

\begin{equation}
Pr(W|N,p) = \frac{N!}{(W! (N-W)!))} p^W (1-p)^{N-W}
\end{equation}

where W = number of times we hit water
      N = number of times globe is tossed
      p = probability of water
      1 - p = probability of land
      
If the globe was tossed 2 times, we would have hit water for 0, 1, 2 times.
```{r}
dbinom(0:2, size = 2, prob = 0.7)
```

With a 0.7 probability of hitting water, we would have landed on water
  * 0 times with a probability of 0.09
  * 1 times with a probability of 0.42, and
  * 2 times with a probability of 0.49
  
Using these probabilities, we can simulate observations. For example, if we want to simulate observing 1 water out of 2 tosses with a 0.7 probability of hitting water:
```{r}
rbinom(1, size = 2, prob = 0.7)
```

So we got 1 water in 2 tosses.
If it was 0, it would have been 0 water in 2 tosses.
If it was 2, it would be 2 water in 2 tosses.
Lets simulate more observations:

```{r}
rbinom(10, size = 2, prob = 0.7)
```

Generating 100000 dummy values:
```{r}
dummy_w <- rbinom(1e5, size = 2, prob = 0.7)
table(dummy_w) / 1e5
```
These values are close to the dbinom's analytical output above.

Now let's simulate 9 tosses:
```{r}
dummy_w <- rbinom(1e5, size = 9, prob = 0.7)
simplehist(dummy_w, xlab = "dummy water counts")
```

In this book, the posterior distribution is deduced logically. Then samples can be drawn from it.

### 3.3.2 Model checking

